,name,tensor_util,single_util,double_util,time_%,time_ms,calls,avg_ms
55,volta_sgemm_64x64_nt,0,6,0,10.879934,3.3787279999999997,59381,0.056899
78,"void at::native::vectorized_elementwise_kernel<int=4, at::native::AddFunctor<float>, at::detail::Array<char*, int=3>>(int, float, at::native::AddFunctor<float>)",0,1,0,10.685696,3.3184080000000002,825508,0.004019
26,"void cudnn::cnn::wgrad_alg1_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=0>(int, int, int, float const *, int, float*, float const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",0,7,0,6.0342400000000005,1.8739139999999999,3128,0.5990770000000001
49,volta_sgemm_64x64_nn,0,5,0,5.563262,1.7276529999999999,19467,0.088747
62,"void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)",0,1,0,5.363925,1.6657490000000001,69475,0.023976
70,"void cudnn::cnn::wgrad_alg1_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=0>(int, int, int, float const *, int, float*, float const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",0,2,0,5.16761,1.604784,9379,0.171104
10,"void implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=1, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_conv_params, __int64, int, float, float, int, float const *, float const *, bool, int, int)",0,5,0,4.838693,1.50264,18941,0.079332
14,volta_sgemm_128x32_nt,0,5,0,4.333213,1.345665,18752,0.071761
72,volta_gcgemm_64x32_nt,0,8,0,4.015893,1.2471219999999998,12530,0.09953
18,volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1,0,9,0,3.15393,0.9794430000000001,12830,0.07633999999999999
51,"void cudnn::detail::dgrad_alg1_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_alg1_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)",0,2,0,2.895882,0.899307,3126,0.287686
64,"void cudnn::detail::dgrad2d_alg1_1<float, int=0, int=5, int=6, int=4, int=3, int=4, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad2d_alg1_1<float, int=0, int=5, int=6, int=4, int=3, int=4, bool=0, bool=1>*, kernel_grad_params, __int64, int, __int64, int, float, int, int)",0,8,0,2.854317,0.8863989999999999,3127,0.283466
46,"void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)",0,1,1,2.799273,0.8693049999999999,43755,0.019867
56,_ZN2at6native29vectorized_elementwise_kernelILi4EZNS0_21threshold_kernel_implIfEEvRNS_14TensorIteratorET_S5_EUlffE_NS_6detail5ArrayIPcLi3EEEEEviT0_T1_,0,1,0,2.4174729999999998,0.750738,107593,0.006977
0,"void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)",0,2,0,2.3684830000000003,0.735525,69475,0.010586
38,"void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",0,2,0,2.271783,0.705495,69475,0.010154
86,"void at::native::vectorized_elementwise_kernel<int=4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, int=2>>(int, float, float)",0,0,0,1.9338490000000002,0.60055,193688,0.0031
79,"void cudnn::detail::dgrad_alg1_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_alg1_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)",0,5,0,1.904686,0.591494,6252,0.094608
4,"void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",0,1,0,1.689124,0.524552,43755,0.011988
11,"void cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>(float, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnnTensorStruct, float const *, float, float const , float, cudnnTensorStruct*, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const *, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>*, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const *, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const , cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const , cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>)",0,2,0,1.6037270000000001,0.498032,15625,0.031874
2,"void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)",0,1,0,1.5903100000000001,0.49386499999999994,43755,0.011287
34,"void cudnn::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>(float, float, float, float, cudnnTensorStruct, float const *, cudnn::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, float const , cudnn::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float*, float const *, float const , float const , float, cudnn::reduced_divisor, int, float*, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",0,2,0,1.4563110000000001,0.45225299999999996,46875,0.009648
35,"void cudnn::detail::dgrad2d_alg1_1<float, int=0, int=6, int=7, int=5, int=4, int=5, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad2d_alg1_1<float, int=0, int=6, int=7, int=5, int=4, int=5, bool=0, bool=1>*, kernel_grad_params, __int64, int, __int64, int, float, int, int)",0,7,0,1.398132,0.43418500000000004,3127,0.13885
21,"void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<float>, at::detail::Array<char*, int=1>>(int, float, at::native::FillFunctor<float>)",0,1,0,1.333732,0.41418599999999994,196813,0.002104
61,"void fft2d_r2c_32x32<float, bool=1, unsigned int=0, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",0,4,0,1.3159129999999999,0.408652,12505,0.032679
76,"void cudnn::bn_fw_tr_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>(cudnnTensorStruct, float const *, cudnn::bn_fw_tr_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",0,2,0,1.179139,0.366178,46875,0.007811
74,volta_sgemm_32x128_nn,0,8,0,1.054314,0.327414,9379,0.034908999999999996
22,"void fft2d_c2r_32x32<float, bool=0, bool=0, unsigned int=0, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)",0,3,0,1.03437,0.32122,12524,0.025648
81,volta_sgemm_32x128_nt,0,8,0,1.013807,0.314835,9376,0.033578
84,volta_scudnn_128x32_stridedB_splitK_small_nn_v1,0,6,0,0.821321,0.25505900000000004,3127,0.081566
59,volta_scudnn_128x64_stridedB_splitK_small_nn_v1,0,7,0,0.789209,0.24508600000000003,3127,0.078377
60,"void fft2d_r2c_32x32<float, bool=0, unsigned int=1, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",0,4,0,0.751743,0.23345100000000002,3154,0.074017
13,"void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int=512, bool=1, int=1>(cudnnTensorStruct, float const *, cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int=512, bool=1, int=1>, cudnnTensorStruct*, float const *, float const , cudnnTensorStruct*, cudnnTensorStruct*, cudnnTensorStruct**, float const *, float const *, float const *, cudnnTensorStruct*, cudnnTensorStruct*)",0,3,0,0.59096,0.18352100000000002,15625,0.011745
87,"void cudnn::bn_fw_inf_1C11_kernel_NCHW<float, float, bool=1, int=1>(float, cudnn::bn_fw_inf_1C11_kernel_NCHW<float, float, bool=1, int=1>, cudnnTensorStruct, float const *, float, cudnnTensorStruct*, float, cudnn::bn_fw_inf_1C11_kernel_NCHW<float, float, bool=1, int=1> const *, cudnn::bn_fw_inf_1C11_kernel_NCHW<float, float, bool=1, int=1> const , cudnn::bn_fw_inf_1C11_kernel_NCHW<float, float, bool=1, int=1> const , cudnn::bn_fw_inf_1C11_kernel_NCHW<float, float, bool=1, int=1> const , cudnn::bn_fw_inf_1C11_kernel_NCHW<float, float, bool=1, int=1>)",0,0,0,0.364969,0.11334000000000001,1580,0.071734
33,"void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<at::native::AddFunctor<long>>, at::detail::Array<char*, int=2>>(int, long, at::native::AddFunctor<long>)",0,1,0,0.30931,0.096055,62500,0.001536
88,[CUDA memcpy HtoD],0,0,0,0.27865300000000004,0.086535,6536,0.013238999999999999
20,"void implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=1, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_conv_params, __int64, int, float, float, int, float const *, float const *, bool, int, int)",0,4,0,0.232609,0.072236,3128,0.023093000000000002
24,"void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)",0,1,0,0.22344,0.069388,15653,0.004432
89,"void implicit_convolve_sgemm<float, float, int=512, int=6, int=8, int=3, int=3, int=5, int=1, bool=0, bool=1, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_conv_params, __int64, int, float, float, int, float const *, float const *, bool, int, int)",0,0,0,0.152411,0.047331,84,0.563462
90,[CUDA memset],0,0,0,0.14938900000000002,0.046392,28185,0.001645
30,"void explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0>(int, int, int, float const *, int, float const *, int, float*, kernel_conv_params, __int64, int, __int64, int, float, float, int, float const *, float const *)",0,8,0,0.139042,0.043179,86,0.502081
65,"void cudnn::winograd::generateWinogradTilesKernel<int=0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",0,1,0,0.135077,0.041948,12830,0.0032689999999999998
58,"void gemmSN_TN_kernel_64addr<float, int=128, int=16, int=2, int=4, int=8, int=9, bool=0, cublasGemvTensorStridedBatched<float const >, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<float const , cublasGemvTensorStridedBatched<float const >, float>)",0,1,0,0.10391800000000001,0.032272,3126,0.010323
91,"void implicit_convolve_sgemm<float, float, int=128, int=6, int=7, int=3, int=3, int=5, int=1, bool=0, bool=1, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_conv_params, __int64, int, float, float, int, float const *, float const *, bool, int, int)",0,0,0,0.072012,0.022363,170,0.131548
80,"void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, int=4>>(float)",0,2,0,0.067525,0.02097,3204,0.0065439999999999995
66,"void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, int=2>, OffsetCalculator<int=1, unsigned int>, OffsetCalculator<int=1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, float, float, at::native::MulScalarFunctor<float, float>, char*, int=2, at::detail::Array<char*, int=2>)",0,1,0,0.064976,0.020178,3125,0.006456
92,volta_gcgemm_64x64_nt,0,0,0,0.058704,0.01823,17,1.072381
3,_ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE0_clEvENKUlvE6_clEvEUlfE_NS_6detail5ArrayIPcLi2EEE16OffsetCalculatorILi1EjESC_NS0_6memory15LoadWithoutCastENSD_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_,0,1,0,0.050054,0.015544,3204,0.004850999999999999
31,_ZN2at6native13reduce_kernelILi256ELi2ENS0_8ReduceOpIfNS0_14func_wrapper_tIfZNS0_11sum_functorIfffEclERNS_14TensorIteratorEEUlffE_EEjfLi4EEEEEvT1_,0,1,0,0.048099,0.014937,3125,0.004779
7,"void gemmSN_NN_kernel<float, int=256, int=4, int=2, int=8, int=4, int=4, bool=0, cublasGemvTensorStridedBatched<float const >, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<float const , cublasGemvTensorStridedBatched<float const >, float>)",0,1,0,0.042008,0.013045,3125,0.004174000000000001
25,"void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)",0,1,0,0.040779,0.012664,3204,0.003952000000000001
69,cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams),0,1,0,0.040764,0.012659,6257,0.002023
73,cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams),0,1,0,0.03991,0.012394,6257,0.00198
8,"void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)",0,1,0,0.026820999999999998,0.008329000000000001,3125,0.002665
39,"void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const *, cudnnTensor4dStruct*)",0,2,0,0.026691000000000003,0.008289,100,0.082886
54,"void _GLOBAL__N__54_tmpxft_000035b1_00000000_12_SoftMax_compute_80_cpp1_ii_a3310042::softmax_warp_forward<float, float, float, int=4, bool=1>(float*, float const *, int, int, int)",0,1,0,0.0254,0.007888,3204,0.002461
83,"void fft2d_r2c_32x32<float, bool=0, unsigned int=1, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",0,5,0,0.021921,0.006807,16,0.425462
85,volta_cgemm_32x64_tn,0,7,0,0.018855,0.005855,7,0.836492
42,"void _GLOBAL__N__54_tmpxft_000035b1_00000000_12_SoftMax_compute_80_cpp1_ii_a3310042::softmax_warp_backward<float, float, float, int=4, bool=1>(float*, float const *, float const , int, int, int)",0,1,0,0.018604,0.005777,3125,0.001848
93,volta_scudnn_128x64_relu_interior_nn_v1,0,0,0,0.017240000000000002,0.005354,80,0.06692200000000001
68,"void cudnn::cnn::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, int=512>(int, int, int, float const *, int, cudnn::cnn::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, int=512>*, float const , kernel_grad_params, __int64, int, float, int, int, int, int)",0,4,0,0.010109,0.003139,12,0.26160700000000003
5,"void cudnn::detail::dgrad_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0>*, kernel_grad_params, __int64, int, __int64, int, float, int, int, int)",0,5,0,0.008856999999999999,0.002751,20,0.137527
23,"void explicit_convolve_sgemm<float, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>(int, int, int, float const *, int, float const *, int, float*, kernel_conv_params, __int64, int, __int64, int, float, float, int, float const *, float const *)",0,4,0,0.008458,0.002627,11,0.238792
57,volta_cgemm_64x32_tn,0,9,0,0.008376,0.002601,7,0.37159699999999996
50,"void fft2d_r2c_16x16<float>(float2*, float const *, int, int, int, int, int, int, int, int)",0,3,0,0.0069370000000000005,0.002154,16,0.134634
48,volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1,0,9,0,0.005779,0.001795,4,0.44863400000000003
40,"void fft2d_c2r_32x32<float, bool=1, bool=0, unsigned int=0, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)",0,3,0,0.004887,0.001518,12,0.126467
41,"void fft2d_c2r_32x32<float, bool=0, bool=0, unsigned int=1, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)",0,3,0,0.004854,0.001507,15,0.100495
94,volta_scudnn_128x32_relu_small_nn_v1,0,0,0,0.004547,0.0014119999999999998,3,0.47063900000000003
1,"void flip_filter<float, float>(float*, float const *, int, int, int, int)",0,1,0,0.004228,0.0013130000000000001,15,0.08753999999999999
36,"void fft2d_r2c_32x32<float, bool=0, unsigned int=0, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",0,3,0,0.003942,0.001224,28,0.043725
16,"void pointwise_mult_and_sum_complex<float2, int=8, int=4>(float2*, float2*, float2*, int, int, int, int, int, float2)",0,5,0,0.0037920000000000002,0.001178,5,0.23554899999999998
95,volta_sgemm_32x32_sliced1x4_tn,0,0,0,0.0037090000000000005,0.001152,78,0.014768
82,"void fft2d_r2c_64x64<float, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int)",0,5,0,0.003274,0.001017,14,0.072614
77,"void transpose_readWrite_alignment_kernel<float2, float2, int=1, bool=0, int=6, int=4, int=4>(cublasTransposeParams<float2>, float2 const *, float2*, float2 const *)",0,1,0,0.003065,0.0009519999999999999,6,0.158621
75,"void cudnn::detail::dgrad_alg1_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_alg1_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)",0,6,0,0.002877,0.000893,1,0.893332
15,"void fft2d_c2r_64x64<float, bool=0, bool=1>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",0,3,0,0.00286,0.0008880000000000001,7,0.126896
96,volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_large_nhwc_tn_v1,0,0,0,0.002859,0.0008880000000000001,1,0.8877649999999999
71,"void fft2d_c2r_16x16<float, bool=0>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",0,3,0,0.002838,0.0008810000000000001,8,0.11015799999999999
6,"void cudnn::cnn::wgrad_alg0_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, int=512>(int, int, int, float const *, int, cudnn::cnn::wgrad_alg0_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, int=512>*, float const , kernel_grad_params, __int64, int, float, int, int, int, int)",0,4,0,0.0027949999999999997,0.000868,8,0.10850599999999999
32,volta_scudnn_128x64_stridedB_small_nn_v1,0,8,0,0.002457,0.000763,2,0.38143499999999997
97,"void precomputed_convolve_sgemm<float, int=128, int=6, int=7, int=3, int=3, int=5, int=1, bool=0>(int, int, int, float const *, int, float*, float const *, kernel_conv_params, __int64, int, float, float, int, float const *, float const *, int*)",0,0,0,0.002245,0.000697,1,0.697271
98,"void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<float, at::native::MaxOps<float>, unsigned int, float, int=4>>(float)",0,0,0,0.0021609999999999997,0.000671,79,0.008494
9,"void cudnn::cnn::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, int=512>(int, int, int, float const *, int, cudnn::cnn::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, int=512>*, float const , kernel_grad_params, __int64, int, float, int, int, int, int)",0,5,0,0.00195,0.000606,8,0.075695
99,volta_scudnn_128x128_relu_small_nn_v1,0,0,0,0.001663,0.000516,2,0.25817199999999996
47,"void cudnn::cnn::wgrad_alg1_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=0>(int, int, int, float const *, int, float*, float const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",0,4,0,0.001648,0.000512,1,0.5118010000000001
100,volta_scudnn_128x64_relu_xregs_large_nn_v1,0,0,0,0.001523,0.00047300000000000006,1,0.47311400000000003
37,cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams),0,1,0,0.001493,0.00046399999999999995,98,0.00473
101,_ZN2at6native13reduce_kernelILi512ELi1ENS0_8ReduceOpIlNS0_14func_wrapper_tIlZNS0_11sum_functorIlllEclERNS_14TensorIteratorEEUlllE_EEjlLi4EEEEEvT1_,0,0,0,0.0014470000000000002,0.000449,79,0.005686
52,volta_scudnn_128x32_relu_medium_nn_v1,0,3,0,0.0014449999999999999,0.000449,2,0.22431700000000002
102,_ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE0_clEvENKUlvE10_clEvEUllE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESC_NS0_6memory12LoadWithCastILi1EEENSD_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_,0,0,0,0.001187,0.00036899999999999997,79,0.004666
17,volta_scudnn_128x128_stridedB_splitK_medium_nn_v1,0,6,0,0.001125,0.000349,2,0.17466900000000002
28,"void explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>(int, int, int, float const *, int, float const *, int, float*, kernel_conv_params, __int64, int, __int64, int, float, float, int, float const *, float const *)",0,5,0,0.0009660000000000001,0.0003,3,0.10002
103,[CUDA memcpy DtoH],0,0,0,0.000926,0.000288,190,0.001513
45,volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1,0,5,0,0.000842,0.000261,1,0.261372
53,"void wgrad2d_grouped_direct_kernel<float, float, float, cudnnTensorFormat_t=0>(cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)",0,4,0,0.000788,0.000245,1,0.244796
104,"void splitKreduce_kernel<float, float, float, float>(cublasSplitKParams<float>, float const *, float const *, float*, float const *, float const *, float const *)",0,0,0,0.000759,0.000236,78,0.0030210000000000002
19,volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1,0,8,0,0.000709,0.00022,2,0.110062
105,[CUDA memcpy DtoD],0,0,0,0.000651,0.000202,62,0.003259
43,"void nchwToNhwcKernel<float, float, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, float const *, float*, float, float)",0,3,0,0.0006259999999999999,0.000194,14,0.013880000000000002
106,"void at::native::vectorized_elementwise_kernel<int=4, at::native::CompareEqFunctor<long>, at::detail::Array<char*, int=3>>(int, long, at::native::CompareEqFunctor<long>)",0,0,0,0.0005099999999999999,0.00015800000000000002,79,0.002003
44,"void nhwcToNchwKernel<float, float, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, float const *, float*, float, float)",0,2,0,0.00022200000000000003,6.9e-05,7,0.009842
67,volta_scudnn_128x128_relu_medium_nn_v1,0,7,0,9.8e-05,2.9999999999999997e-05,1,0.030463
27,"void nchwToFoldedNchwKernel<float, float, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, float const *, float*, int, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",0,3,0,2.6000000000000002e-05,8e-06,1,0.008
12,"void foldedNchwToNchwKernel<float, float, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, int, int, int, float const *, float*, int, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",0,4,0,2.3e-05,7.000000000000001e-06,1,0.00704
63,"void nchwAddPaddingKernel<float, float, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, int, int, int, int, float const *, float*, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",0,2,0,1.6e-05,5e-06,1,0.005024
29,cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams),0,1,0,1.4999999999999999e-05,5e-06,2,0.002288
107,"void cudnn::cnn::kern_precompute_indices<bool=0>(int*, int, int, int, int, int, int)",0,0,0,7.000000000000001e-06,2e-06,1,0.002112
