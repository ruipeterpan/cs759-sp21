==34706== NVPROF is profiling process 34706, command: /home/ruipan/anaconda3/bin/python cv_benchmark.py --apex-amp O1 --model resnet18 --dataset cifar10 --batch-size 16 --epochs 1 --breakpoint 1
==34706== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==34706== Profiling application: /home/ruipan/anaconda3/bin/python cv_benchmark.py --apex-amp O1 --model resnet18 --dataset cifar10 --batch-size 16 --epochs 1 --breakpoint 1
==34706== Profiling result:
==34706== Metric result:
"Device","Kernel","Invocations","Metric Name","Metric Description","Min","Max","Avg"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<__half, __half, int=1024, int=6, int=7, int=3, int=3, int=5, int=1, bool=0, bool=1, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<__half, __half, int=1024, int=6, int=7, int=3, int=3, int=5, int=1, bool=0, bool=1, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Mid (5)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<__half, __half, int=1024, int=6, int=7, int=3, int=3, int=5, int=1, bool=0, bool=1, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<__half, bool=0, unsigned int=1, bool=0>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",21,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<__half, bool=0, unsigned int=1, bool=0>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",21,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (4)","Mid (6)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<__half, bool=0, unsigned int=1, bool=0>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",21,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_s884cudnn_fp16_128x128_ldg8_wgrad_idx_exp_interior_nhwc_nt_v1",3,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Low (3)","High (8)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","volta_s884cudnn_fp16_128x128_ldg8_wgrad_idx_exp_interior_nhwc_nt_v1",3,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","volta_s884cudnn_fp16_128x128_ldg8_wgrad_idx_exp_interior_nhwc_nt_v1",3,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE0_clEvENKUlvE18_clEvEUlN3c104HalfEE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESE_NS0_6memory12LoadWithCastILi1EEENSF_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_",24,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE0_clEvENKUlvE18_clEvEUlN3c104HalfEE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESE_NS0_6memory12LoadWithCastILi1EEENSF_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_",24,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (2)","Low (1)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE0_clEvENKUlvE18_clEvEUlN3c104HalfEE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESE_NS0_6memory12LoadWithCastILi1EEENSF_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_",24,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_scudnn_fp16_128x64_relu_interior_nn_v1",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_scudnn_fp16_128x64_relu_interior_nn_v1",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (6)","Mid (6)","Mid (6)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_scudnn_fp16_128x64_relu_interior_nn_v1",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void explicit_convolve_sgemm<__half, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>(int, int, int, __half const *, int, __half const *, int, __half*, kernel_conv_params, __int64, int, __int64, int, float, float, int, __half const *, __half const *)",8,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void explicit_convolve_sgemm<__half, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>(int, int, int, __half const *, int, __half const *, int, __half*, kernel_conv_params, __int64, int, __int64, int, float, float, int, __half const *, __half const *)",8,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (4)","High (7)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","void explicit_convolve_sgemm<__half, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>(int, int, int, __half const *, int, __half const *, int, __half*, kernel_conv_params, __int64, int, __int64, int, float, float, int, __half const *, __half const *)",8,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_alg1_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=1>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad_alg1_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_alg1_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=1>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad_alg1_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (4)","High (7)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_alg1_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=1>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad_alg1_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<__half, __half, int=128, int=6, int=7, int=3, int=3, int=5, int=1, bool=0, bool=1, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<__half, __half, int=128, int=6, int=7, int=3, int=3, int=5, int=1, bool=0, bool=1, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Mid (5)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<__half, __half, int=128, int=6, int=7, int=3, int=3, int=5, int=1, bool=0, bool=1, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_scudnn_fp16_128x32_relu_small_nn_v1",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_scudnn_fp16_128x32_relu_small_nn_v1",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (4)","Mid (4)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_scudnn_fp16_128x32_relu_small_nn_v1",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void pointwise_mult_and_sum_complex<float2, int=8, int=4>(float2*, float2*, float2*, int, int, int, int, int, float2)",3,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void pointwise_mult_and_sum_complex<float2, int=8, int=4>(float2*, float2*, float2*, int, int, int, int, int, float2)",3,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","High (7)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","void pointwise_mult_and_sum_complex<float2, int=8, int=4>(float2*, float2*, float2*, int, int, int, int, int, float2)",3,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<__half, bool=0, unsigned int=1, bool=1>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",8,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<__half, bool=0, unsigned int=1, bool=1>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",8,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (4)","Mid (6)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<__half, bool=0, unsigned int=1, bool=1>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",8,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1",9,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1",9,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (5)","Max (10)","High (8)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1",9,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_128x128_ldg8_dgrad_f2f_exp_small_nhwc2nchw_tt_v1",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Low (3)","Mid (4)","Low (3)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_128x128_ldg8_dgrad_f2f_exp_small_nhwc2nchw_tt_v1",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_128x128_ldg8_dgrad_f2f_exp_small_nhwc2nchw_tt_v1",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_s884cudnn_fp16_64x64_sliced1x4_ldg8_wgrad_idx_exp_interior_nhwc_nt_v1",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Low (1)","Low (3)","Low (2)"
"Tesla V100-PCIE-16GB (0)","volta_s884cudnn_fp16_64x64_sliced1x4_ldg8_wgrad_idx_exp_interior_nhwc_nt_v1",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","volta_s884cudnn_fp16_64x64_sliced1x4_ldg8_wgrad_idx_exp_interior_nhwc_nt_v1",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_bw_1C11_singleread_fp16<int=512, int=1, int=2, int=14>(float, float, float, float, cudnnTensorStruct, __half2 const *, cudnn::bn_bw_1C11_singleread_fp16<int=512, int=1, int=2, int=14>, __half2 const , cudnn::bn_bw_1C11_singleread_fp16<int=512, int=1, int=2, int=14>, cudnnTensorStruct*, float const *, float*, float const *, float const , float const , float, cudnn::reduced_divisor, int, float*, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_bw_1C11_singleread_fp16<int=512, int=1, int=2, int=14>(float, float, float, float, cudnnTensorStruct, __half2 const *, cudnn::bn_bw_1C11_singleread_fp16<int=512, int=1, int=2, int=14>, __half2 const , cudnn::bn_bw_1C11_singleread_fp16<int=512, int=1, int=2, int=14>, cudnnTensorStruct*, float const *, float*, float const *, float const , float const , float, cudnn::reduced_divisor, int, float*, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (2)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_bw_1C11_singleread_fp16<int=512, int=1, int=2, int=14>(float, float, float, float, cudnnTensorStruct, __half2 const *, cudnn::bn_bw_1C11_singleread_fp16<int=512, int=1, int=2, int=14>, __half2 const , cudnn::bn_bw_1C11_singleread_fp16<int=512, int=1, int=2, int=14>, cudnnTensorStruct*, float const *, float*, float const *, float const , float const , float, cudnn::reduced_divisor, int, float*, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_32x32<__half, bool=0, bool=0, unsigned int=0, bool=0, bool=0>(__half*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, __half*, __half*, int2, int, int)",12,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_32x32<__half, bool=0, bool=0, unsigned int=0, bool=0, bool=0>(__half*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, __half*, __half*, int2, int, int)",12,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (3)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_32x32<__half, bool=0, bool=0, unsigned int=0, bool=0, bool=0>(__half*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, __half*, __half*, int2, int, int)",12,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)",4,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)",4,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (3)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void nhwcToNchwKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)",4,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_128x128_ldg8_relu_f2f_exp_interior_nhwc2nchw_tn_v1",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Low (3)","Low (3)","Low (3)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_128x128_ldg8_relu_f2f_exp_interior_nhwc2nchw_tn_v1",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_128x128_ldg8_relu_f2f_exp_interior_nhwc2nchw_tn_v1",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_16x16<__half, bool=0>(__half*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, __half*, __half*)",6,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_16x16<__half, bool=0>(__half*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, __half*, __half*)",6,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Mid (4)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_16x16<__half, bool=0>(__half*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, __half*, __half*)",6,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_sgemm_fp16_128x32_nt",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_sgemm_fp16_128x32_nt",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Low (3)","Low (3)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_sgemm_fp16_128x32_nt",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)",13,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)",13,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (2)","Low (1)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)",13,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_16x16<__half>(float2*, __half const *, int, int, int, int, int, int, int, int)",12,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_16x16<__half>(float2*, __half const *, int, int, int, int, int, int, int, int)",12,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Mid (4)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_16x16<__half>(float2*, __half const *, int, int, int, int, int, int, int, int)",12,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","_Z25multi_tensor_apply_kernelI18TensorListMetadataILi2EE12ScaleFunctorIffEJfEEviPViT_T0_DpT1_",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","_Z25multi_tensor_apply_kernelI18TensorListMetadataILi2EE12ScaleFunctorIffEJfEEviPViT_T0_DpT1_",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","_Z25multi_tensor_apply_kernelI18TensorListMetadataILi2EE12ScaleFunctorIffEJfEEviPViT_T0_DpT1_",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<at::native::AddFunctor<long>>, at::detail::Array<char*, int=2>>(int, long, at::native::AddFunctor<long>)",20,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<at::native::AddFunctor<long>>, at::detail::Array<char*, int=2>>(int, long, at::native::AddFunctor<long>)",20,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<at::native::AddFunctor<long>>, at::detail::Array<char*, int=2>>(int, long, at::native::AddFunctor<long>)",20,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::ops::convertTensor_kernel<__half, float, float, int=0>(float, __half const *, cudnn::ops::convertTensor_kernel<__half, float, float, int=0>, float*, unsigned long)",28,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::ops::convertTensor_kernel<__half, float, float, int=0>(float, __half const *, cudnn::ops::convertTensor_kernel<__half, float, float, int=0>, float*, unsigned long)",28,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (2)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::ops::convertTensor_kernel<__half, float, float, int=0>(float, __half const *, cudnn::ops::convertTensor_kernel<__half, float, float, int=0>, float*, unsigned long)",28,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void gemmSN_TN_kernel_64addr<float, int=128, int=16, int=2, int=4, int=8, int=9, bool=0, cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half>>(cublasGemmSmallNParams<__half const , cublasGemvTensorStridedBatched<__half const >, float>)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void gemmSN_TN_kernel_64addr<float, int=128, int=16, int=2, int=4, int=8, int=9, bool=0, cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half>>(cublasGemmSmallNParams<__half const , cublasGemvTensorStridedBatched<__half const >, float>)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void gemmSN_TN_kernel_64addr<float, int=128, int=16, int=2, int=4, int=8, int=9, bool=0, cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half>>(cublasGemmSmallNParams<__half const , cublasGemvTensorStridedBatched<__half const >, float>)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<__half, int=0, int=6, int=7, int=5, int=4, int=5, bool=0, bool=1>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad2d_alg1_1<__half, int=0, int=6, int=7, int=5, int=4, int=5, bool=0, bool=1>*, kernel_grad_params, __int64, int, __int64, int, float, int, int)",6,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<__half, int=0, int=6, int=7, int=5, int=4, int=5, bool=0, bool=1>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad2d_alg1_1<__half, int=0, int=6, int=7, int=5, int=4, int=5, bool=0, bool=1>*, kernel_grad_params, __int64, int, __int64, int, float, int, int)",6,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (7)","High (8)","High (7)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<__half, int=0, int=6, int=7, int=5, int=4, int=5, bool=0, bool=1>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad2d_alg1_1<__half, int=0, int=6, int=7, int=5, int=4, int=5, bool=0, bool=1>*, kernel_grad_params, __int64, int, __int64, int, float, int, int)",6,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)",34,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)",34,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (2)","Low (1)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)",34,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradForwardData4x4<float, __half>(cudnn::winograd_nonfused::WinogradDataParams<float, __half>)",18,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradForwardData4x4<float, __half>(cudnn::winograd_nonfused::WinogradDataParams<float, __half>)",18,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Mid (4)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradForwardData4x4<float, __half>(cudnn::winograd_nonfused::WinogradDataParams<float, __half>)",18,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native29vectorized_elementwise_kernelILi4EZNS0_21threshold_kernel_implIN3c104HalfEEEvRNS_14TensorIteratorET_S7_EUlS4_S4_E_NS_6detail5ArrayIPcLi3EEEEEviT0_T1_",34,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native29vectorized_elementwise_kernelILi4EZNS0_21threshold_kernel_implIN3c104HalfEEEvRNS_14TensorIteratorET_S7_EUlS4_S4_E_NS_6detail5ArrayIPcLi3EEEEEviT0_T1_",34,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native29vectorized_elementwise_kernelILi4EZNS0_21threshold_kernel_implIN3c104HalfEEEvRNS_14TensorIteratorET_S7_EUlS4_S4_E_NS_6detail5ArrayIPcLi3EEEEEviT0_T1_",34,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_scudnn_fp16_128x128_relu_small_nn_v1",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_scudnn_fp16_128x128_relu_small_nn_v1",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (9)","Max (10)","High (9)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_scudnn_fp16_128x128_relu_small_nn_v1",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void _GLOBAL__N__54_tmpxft_000035b1_00000000_12_SoftMax_compute_80_cpp1_ii_a3310042::softmax_warp_backward<float, float, float, int=4, bool=1>(float*, float const *, float const , int, int, int)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void _GLOBAL__N__54_tmpxft_000035b1_00000000_12_SoftMax_compute_80_cpp1_ii_a3310042::softmax_warp_backward<float, float, float, int=4, bool=1>(float*, float const *, float const , int, int, int)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void _GLOBAL__N__54_tmpxft_000035b1_00000000_12_SoftMax_compute_80_cpp1_ii_a3310042::softmax_warp_backward<float, float, float, int=4, bool=1>(float*, float const *, float const , int, int, int)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nchwAddPaddingKernel<__half, __half, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, int, int, int, int, __half const *, __half*, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nchwAddPaddingKernel<__half, __half, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, int, int, int, int, __half const *, __half*, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Mid (4)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void nchwAddPaddingKernel<__half, __half, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, int, int, int, int, __half const *, __half*, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (5)","Mid (5)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<__half, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=1>(int, int, int, __half const *, int, float*, __half const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",3,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<__half, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=1>(int, int, int, __half const *, int, float*, __half const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",3,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (2)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<__half, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=1>(int, int, int, __half const *, int, float*, __half const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",3,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_32x32<__half, bool=1, bool=0, unsigned int=0, bool=0, bool=0>(__half*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, __half*, __half*, int2, int, int)",6,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_32x32<__half, bool=1, bool=0, unsigned int=0, bool=0, bool=0>(__half*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, __half*, __half*, int2, int, int)",6,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Mid (5)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_32x32<__half, bool=1, bool=0, unsigned int=0, bool=0, bool=0>(__half*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, __half*, __half*, int2, int, int)",6,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_32x32<__half, bool=0, bool=0, unsigned int=1, bool=0, bool=0>(__half*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, __half*, __half*, int2, int, int)",12,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_32x32<__half, bool=0, bool=0, unsigned int=1, bool=0, bool=0>(__half*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, __half*, __half*, int2, int, int)",12,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Mid (6)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_32x32<__half, bool=0, bool=0, unsigned int=1, bool=0, bool=0>(__half*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, __half*, __half*, int2, int, int)",12,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=0>(int, int, int, __half const *, int, float*, __half const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",6,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=0>(int, int, int, __half const *, int, float*, __half const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",6,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (7)","High (8)","High (7)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=0>(int, int, int, __half const *, int, float*, __half const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",6,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeWgradOffsetsKernel(cask_cudnn::ComputeWgradOffsetsParams)",13,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeWgradOffsetsKernel(cask_cudnn::ComputeWgradOffsetsParams)",13,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeWgradOffsetsKernel(cask_cudnn::ComputeWgradOffsetsParams)",13,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_64x64<__half, bool=0, bool=1>(__half*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, __half*, __half*)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_64x64<__half, bool=0, bool=1>(__half*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, __half*, __half*)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Mid (6)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_64x64<__half, bool=0, bool=1>(__half*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, __half*, __half*)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_cgemm_64x32_tn",8,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_cgemm_64x32_tn",8,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (8)","Max (10)","High (9)"
"Tesla V100-PCIE-16GB (0)","volta_cgemm_64x32_tn",8,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x64_stridedB_splitK_small_nn_v1",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x64_stridedB_splitK_small_nn_v1",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (6)","High (7)","Mid (6)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x64_stridedB_splitK_small_nn_v1",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_64x64<__half, bool=1>(float2*, __half const *, int, int, int, int, int, int, int, int)",10,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_64x64<__half, bool=1>(float2*, __half const *, int, int, int, int, int, int, int, int)",10,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Mid (6)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_64x64<__half, bool=1>(float2*, __half const *, int, int, int, int, int, int, int, int)",10,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<__half, bool=0, unsigned int=0, bool=0>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",17,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<__half, bool=0, unsigned int=0, bool=0>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",17,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Mid (5)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<__half, bool=0, unsigned int=0, bool=0>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",17,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd::generateWinogradTilesKernel<int=0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",9,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd::generateWinogradTilesKernel<int=0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",9,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (3)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd::generateWinogradTilesKernel<int=0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",9,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_engine<__half, int=512, int=6, int=5, int=3, int=3, int=3, bool=0>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad_engine<__half, int=512, int=6, int=5, int=3, int=3, int=3, bool=0>*, kernel_grad_params, __int64, int, __int64, int, float, int, int, int)",6,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_engine<__half, int=512, int=6, int=5, int=3, int=3, int=3, bool=0>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad_engine<__half, int=512, int=6, int=5, int=3, int=3, int=3, bool=0>*, kernel_grad_params, __int64, int, __int64, int, float, int, int, int)",6,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Mid (5)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_engine<__half, int=512, int=6, int=5, int=3, int=3, int=3, bool=0>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad_engine<__half, int=512, int=6, int=5, int=3, int=3, int=3, bool=0>*, kernel_grad_params, __int64, int, __int64, int, float, int, int, int)",6,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_s884cudnn_fp16_256x128_ldg8_wgrad_idx_exp_interior_nhwc_nt_v1",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Mid (5)","Mid (5)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","volta_s884cudnn_fp16_256x128_ldg8_wgrad_idx_exp_interior_nhwc_nt_v1",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","volta_s884cudnn_fp16_256x128_ldg8_wgrad_idx_exp_interior_nhwc_nt_v1",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nchwToNhwcKernel<float, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, float const *, __half*, float, float)",9,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nchwToNhwcKernel<float, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, float const *, __half*, float, float)",9,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","High (7)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","void nchwToNhwcKernel<float, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, float const *, __half*, float, float)",9,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_bw_1C11_singleread_fp16<int=512, int=1, int=2, int=0>(float, float, float, float, cudnnTensorStruct, __half2 const *, cudnn::bn_bw_1C11_singleread_fp16<int=512, int=1, int=2, int=0>, __half2 const , cudnn::bn_bw_1C11_singleread_fp16<int=512, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float*, float const *, float const , float const , float, cudnn::reduced_divisor, int, float*, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",15,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_bw_1C11_singleread_fp16<int=512, int=1, int=2, int=0>(float, float, float, float, cudnnTensorStruct, __half2 const *, cudnn::bn_bw_1C11_singleread_fp16<int=512, int=1, int=2, int=0>, __half2 const , cudnn::bn_bw_1C11_singleread_fp16<int=512, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float*, float const *, float const , float const , float, cudnn::reduced_divisor, int, float*, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",15,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (3)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_bw_1C11_singleread_fp16<int=512, int=1, int=2, int=0>(float, float, float, float, cudnnTensorStruct, __half2 const *, cudnn::bn_bw_1C11_singleread_fp16<int=512, int=1, int=2, int=0>, __half2 const , cudnn::bn_bw_1C11_singleread_fp16<int=512, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float*, float const *, float const , float const , float, cudnn::reduced_divisor, int, float*, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",15,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_gcgemm_64x32_nt",27,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_gcgemm_64x32_nt",27,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Max (10)","High (8)"
"Tesla V100-PCIE-16GB (0)","volta_gcgemm_64x32_nt",27,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_32x128_nn",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_32x128_nn",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (8)","High (8)","High (8)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_32x128_nn",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_256x64_ldg8_dgrad_f2f_exp_small_nhwc2nchw_tt_v1",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Mid (4)","Mid (4)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_256x64_ldg8_dgrad_f2f_exp_small_nhwc2nchw_tt_v1",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_256x64_ldg8_dgrad_f2f_exp_small_nhwc2nchw_tt_v1",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_128x128_ldg8_splitK_relu_f2f_exp_small_nhwc_tn_v1",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Low (2)","Mid (4)","Low (3)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_128x128_ldg8_splitK_relu_f2f_exp_small_nhwc_tn_v1",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_128x128_ldg8_splitK_relu_f2f_exp_small_nhwc_tn_v1",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE0_clEvENKUlvE6_clEvEUlfE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESC_NS0_6memory12LoadWithCastILi1EEENSD_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_",23,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE0_clEvENKUlvE6_clEvEUlfE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESC_NS0_6memory12LoadWithCastILi1EEENSD_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_",23,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (2)","Low (1)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE0_clEvENKUlvE6_clEvEUlfE_NS_6detail5ArrayIPcLi2EEE23TrivialOffsetCalculatorILi1EjESC_NS0_6memory12LoadWithCastILi1EEENSD_13StoreWithCastEEEviT_T0_T1_T2_T3_T4_",23,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nchwToFoldedNchwKernel<__half, __half, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, int, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nchwToFoldedNchwKernel<__half, __half, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, int, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Low (3)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void nchwToFoldedNchwKernel<__half, __half, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, int, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_32x128_nt",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_32x128_nt",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (8)","High (8)","High (8)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_32x128_nt",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<__half, bool=0, unsigned int=5, bool=0>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<__half, bool=0, unsigned int=5, bool=0>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (4)","Mid (4)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<__half, bool=0, unsigned int=5, bool=0>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x32_stridedB_splitK_small_nn_v1",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x32_stridedB_splitK_small_nn_v1",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (6)","High (7)","Mid (6)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x32_stridedB_splitK_small_nn_v1",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_cgemm_32x64_tn",3,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_cgemm_32x64_tn",3,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (7)","High (8)","High (7)"
"Tesla V100-PCIE-16GB (0)","volta_cgemm_32x64_tn",3,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<__half, bool=1, unsigned int=0, bool=0>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<__half, bool=1, unsigned int=0, bool=0>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (5)","Mid (5)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<__half, bool=1, unsigned int=0, bool=0>(float2*, __half const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradWgradData4x4<float, __half>(cudnn::winograd_nonfused::WinogradDataParams<float, __half>)",14,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradWgradData4x4<float, __half>(cudnn::winograd_nonfused::WinogradDataParams<float, __half>)",14,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Mid (4)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradWgradData4x4<float, __half>(cudnn::winograd_nonfused::WinogradDataParams<float, __half>)",14,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<int>, at::detail::Array<char*, int=1>>(int, int, at::native::FillFunctor<int>)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<int>, at::detail::Array<char*, int=1>>(int, int, at::native::FillFunctor<int>)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<int>, at::detail::Array<char*, int=1>>(int, int, at::native::FillFunctor<int>)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<__half, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=0>(int, int, int, __half const *, int, float*, __half const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<__half, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=0>(int, int, int, __half const *, int, float*, __half const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (3)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<__half, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=0>(int, int, int, __half const *, int, float*, __half const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0>*, kernel_grad_params, __int64, int, __int64, int, float, int, int, int)",14,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0>*, kernel_grad_params, __int64, int, __int64, int, float, int, int, int)",14,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Mid (6)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0>*, kernel_grad_params, __int64, int, __int64, int, float, int, int, int)",14,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<__half, int=128, int=6, int=8, int=3, int=3, int=5, bool=0, bool=0>(int, int, int, __half const *, int, float*, __half const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<__half, int=128, int=6, int=8, int=3, int=3, int=5, bool=0, bool=0>(int, int, int, __half const *, int, float*, __half const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (7)","High (8)","High (7)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<__half, int=128, int=6, int=8, int=3, int=3, int=5, bool=0, bool=0>(int, int, int, __half const *, int, float*, __half const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_alg1_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=0>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad_alg1_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=0>*, kernel_grad_params, __int64, int, float, int)",4,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_alg1_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=0>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad_alg1_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=0>*, kernel_grad_params, __int64, int, float, int)",4,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (7)","High (8)","High (7)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_alg1_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=0>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad_alg1_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=0>*, kernel_grad_params, __int64, int, float, int)",4,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::ops::convertTensor_kernel<float, __half, float, int=0>(float, float const *, cudnn::ops::convertTensor_kernel<float, __half, float, int=0>, __half*, unsigned long)",32,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::ops::convertTensor_kernel<float, __half, float, int=0>(float, float const *, cudnn::ops::convertTensor_kernel<float, __half, float, int=0>, __half*, unsigned long)",32,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (3)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::ops::convertTensor_kernel<float, __half, float, int=0>(float, float const *, cudnn::ops::convertTensor_kernel<float, __half, float, int=0>, __half*, unsigned long)",32,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_128x32_nt",8,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_128x32_nt",8,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (7)","High (7)","High (7)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_128x32_nt",8,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<c10::Half, float>, at::detail::Array<char*, int=2>, OffsetCalculator<int=1, unsigned int>, OffsetCalculator<int=1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, c10::Half, float, at::native::MulScalarFunctor<c10::Half, float>, char*, int=2, at::detail::Array<char*, int=2>)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<c10::Half, float>, at::detail::Array<char*, int=2>, OffsetCalculator<int=1, unsigned int>, OffsetCalculator<int=1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, c10::Half, float, at::native::MulScalarFunctor<c10::Half, float>, char*, int=2, at::detail::Array<char*, int=2>)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (2)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<c10::Half, float>, at::detail::Array<char*, int=2>, OffsetCalculator<int=1, unsigned int>, OffsetCalculator<int=1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, c10::Half, float, at::native::MulScalarFunctor<c10::Half, float>, char*, int=2, at::detail::Array<char*, int=2>)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void explicit_convolve_sgemm<__half, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0>(int, int, int, __half const *, int, __half const *, int, __half*, kernel_conv_params, __int64, int, __int64, int, float, float, int, __half const *, __half const *)",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void explicit_convolve_sgemm<__half, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0>(int, int, int, __half const *, int, __half const *, int, __half*, kernel_conv_params, __int64, int, __int64, int, float, float, int, __half const *, __half const *)",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","High (7)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","void explicit_convolve_sgemm<__half, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0>(int, int, int, __half const *, int, __half const *, int, __half*, kernel_conv_params, __int64, int, __int64, int, float, float, int, __half const *, __half const *)",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, __half>(cudnn::winograd_nonfused::WinogradFilterParams<float, __half>)",18,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, __half>(cudnn::winograd_nonfused::WinogradFilterParams<float, __half>)",18,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (3)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, __half>(cudnn::winograd_nonfused::WinogradFilterParams<float, __half>)",18,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_scudnn_fp16_128x64_relu_small_nn_v1",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_scudnn_fp16_128x64_relu_small_nn_v1",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (8)","High (9)","High (8)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_scudnn_fp16_128x64_relu_small_nn_v1",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_fw_tr_1C11_singleread_fp16<int=512, int=1, int=2, int=0>(cudnnTensorStruct, __half2 const *, cudnn::bn_fw_tr_1C11_singleread_fp16<int=512, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",15,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_fw_tr_1C11_singleread_fp16<int=512, int=1, int=2, int=0>(cudnnTensorStruct, __half2 const *, cudnn::bn_fw_tr_1C11_singleread_fp16<int=512, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",15,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (3)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_fw_tr_1C11_singleread_fp16<int=512, int=1, int=2, int=0>(cudnnTensorStruct, __half2 const *, cudnn::bn_fw_tr_1C11_singleread_fp16<int=512, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",15,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_128x128_ldg8_relu_f2f_exp_large_nhwc2nchw_tn_v1",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","High (7)","High (7)","High (7)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_128x128_ldg8_relu_f2f_exp_large_nhwc2nchw_tn_v1",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_128x128_ldg8_relu_f2f_exp_large_nhwc2nchw_tn_v1",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void precomputed_convolve_sgemm<__half, int=1024, int=5, int=5, int=4, int=3, int=3, int=1, bool=0>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, int*)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void precomputed_convolve_sgemm<__half, int=1024, int=5, int=5, int=4, int=3, int=3, int=1, bool=0>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, int*)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (6)","Mid (6)","Mid (6)"
"Tesla V100-PCIE-16GB (0)","void precomputed_convolve_sgemm<__half, int=1024, int=5, int=5, int=4, int=3, int=3, int=1, bool=0>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, int*)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<float>, at::detail::Array<char*, int=1>>(int, float, at::native::FillFunctor<float>)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<float>, at::detail::Array<char*, int=1>>(int, float, at::native::FillFunctor<float>)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<float>, at::detail::Array<char*, int=1>>(int, float, at::native::FillFunctor<float>)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void explicit_convolve_sgemm<__half, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>(int, int, int, __half const *, int, __half const *, int, __half*, kernel_conv_params, __int64, int, __int64, int, float, float, int, __half const *, __half const *)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void explicit_convolve_sgemm<__half, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>(int, int, int, __half const *, int, __half const *, int, __half*, kernel_conv_params, __int64, int, __int64, int, float, float, int, __half const *, __half const *)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (4)","Mid (4)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void explicit_convolve_sgemm<__half, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>(int, int, int, __half const *, int, __half const *, int, __half*, kernel_conv_params, __int64, int, __int64, int, float, float, int, __half const *, __half const *)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::ops::scalePackedTensor_kernel<__half, float>(cudnnTensor4dStruct, __half*, float)",46,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::ops::scalePackedTensor_kernel<__half, float>(cudnnTensor4dStruct, __half*, float)",46,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (2)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void cudnn::ops::scalePackedTensor_kernel<__half, float>(cudnnTensor4dStruct, __half*, float)",46,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_scudnn_fp16_128x128_stridedB_medium_nn_v1",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_scudnn_fp16_128x128_stridedB_medium_nn_v1",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Max (10)","Max (10)","Max (10)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_scudnn_fp16_128x128_stridedB_medium_nn_v1",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_fw_tr_1C11_singleread_fp16<int=512, int=1, int=2, int=10>(cudnnTensorStruct, __half2 const *, cudnn::bn_fw_tr_1C11_singleread_fp16<int=512, int=1, int=2, int=10>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_fw_tr_1C11_singleread_fp16<int=512, int=1, int=2, int=10>(cudnnTensorStruct, __half2 const *, cudnn::bn_fw_tr_1C11_singleread_fp16<int=512, int=1, int=2, int=10>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (3)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_fw_tr_1C11_singleread_fp16<int=512, int=1, int=2, int=10>(cudnnTensorStruct, __half2 const *, cudnn::bn_fw_tr_1C11_singleread_fp16<int=512, int=1, int=2, int=10>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)",47,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)",47,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Mid (6)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void nchwToNhwcKernel<__half, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, float, float)",47,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, int=2>>(int, float, float)",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, int=2>>(int, float, float)",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, int=2>>(int, float, float)",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE0_clEvENKUlvE18_clEvEUlN3c104HalfEE_NS_6detail5ArrayIPcLi2EEE16OffsetCalculatorILi1EjESE_NS0_6memory15LoadWithoutCastENSF_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE0_clEvENKUlvE18_clEvEUlN3c104HalfEE_NS_6detail5ArrayIPcLi2EEE16OffsetCalculatorILi1EjESE_NS0_6memory15LoadWithoutCastENSF_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE0_clEvENKUlvE18_clEvEUlN3c104HalfEE_NS_6detail5ArrayIPcLi2EEE16OffsetCalculatorILi1EjESE_NS0_6memory15LoadWithoutCastENSF_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_256x128_ldg8_relu_f2f_exp_large_nhwc2nchw_tn_v1",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Mid (6)","Mid (6)","Mid (6)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_256x128_ldg8_relu_f2f_exp_large_nhwc2nchw_tn_v1",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_256x128_ldg8_relu_f2f_exp_large_nhwc2nchw_tn_v1",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<__half, __half, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=1, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)",9,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<__half, __half, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=1, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)",9,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (5)","High (7)","Mid (6)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<__half, __half, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=1, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)",9,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<c10::Half, at::native::MeanOps<float, float>, unsigned int, c10::Half, int=4>>(c10::Half)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<c10::Half, at::native::MeanOps<float, float>, unsigned int, c10::Half, int=4>>(c10::Half)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (2)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<c10::Half, at::native::MeanOps<float, float>, unsigned int, c10::Half, int=4>>(c10::Half)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_scudnn_fp16_128x128_relu_medium_nn_v1",3,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_scudnn_fp16_128x128_relu_medium_nn_v1",3,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (5)","High (8)","Mid (6)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_scudnn_fp16_128x128_relu_medium_nn_v1",3,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native13reduce_kernelILi256ELi2ENS0_8ReduceOpIN3c104HalfENS0_14func_wrapper_tIS4_ZNS0_11sum_functorIS4_fS4_EclERNS_14TensorIteratorEEUlffE_EEjS4_Li4EEEEEvT1_",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native13reduce_kernelILi256ELi2ENS0_8ReduceOpIN3c104HalfENS0_14func_wrapper_tIS4_ZNS0_11sum_functorIS4_fS4_EclERNS_14TensorIteratorEEUlffE_EEjS4_Li4EEEEEvT1_",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native13reduce_kernelILi256ELi2ENS0_8ReduceOpIN3c104HalfENS0_14func_wrapper_tIS4_ZNS0_11sum_functorIS4_fS4_EclERNS_14TensorIteratorEEUlffE_EEjS4_Li4EEEEEvT1_",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_64x64_nn",8,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_64x64_nn",8,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","High (9)","Mid (6)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_64x64_nn",8,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<__half, __half, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=1, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)",24,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<__half, __half, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=1, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)",24,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","High (7)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<__half, __half, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=1, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)",24,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void _GLOBAL__N__54_tmpxft_000035b1_00000000_12_SoftMax_compute_80_cpp1_ii_a3310042::softmax_warp_forward<float, float, float, int=4, bool=1>(float*, float const *, int, int, int)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void _GLOBAL__N__54_tmpxft_000035b1_00000000_12_SoftMax_compute_80_cpp1_ii_a3310042::softmax_warp_forward<float, float, float, int=4, bool=1>(float*, float const *, int, int, int)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void _GLOBAL__N__54_tmpxft_000035b1_00000000_12_SoftMax_compute_80_cpp1_ii_a3310042::softmax_warp_forward<float, float, float, int=4, bool=1>(float*, float const *, int, int, int)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_64x64_nt",12,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_64x64_nt",12,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (4)","High (9)","Mid (6)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_64x64_nt",12,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void flip_filter<__half, __half>(__half*, __half const *, int, int, int, int)",10,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void flip_filter<__half, __half>(__half*, __half const *, int, int, int, int)",10,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void flip_filter<__half, __half>(__half*, __half const *, int, int, int, int)",10,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::kern_precompute_indices<bool=0>(int*, int, int, int, int, int, int)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::kern_precompute_indices<bool=0>(int*, int, int, int, int, int, int)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::kern_precompute_indices<bool=0>(int*, int, int, int, int, int, int)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_128x128_ldg8_splitK_dgrad_f2f_exp_small_nhwc_tt_v1",4,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Low (3)","Mid (5)","Low (3)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_128x128_ldg8_splitK_dgrad_f2f_exp_small_nhwc_tt_v1",4,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_128x128_ldg8_splitK_dgrad_f2f_exp_small_nhwc_tt_v1",4,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::AddFunctor<c10::Half>, at::detail::Array<char*, int=3>>(int, c10::Half, at::native::AddFunctor<c10::Half>)",16,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::AddFunctor<c10::Half>, at::detail::Array<char*, int=3>>(int, c10::Half, at::native::AddFunctor<c10::Half>)",16,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::AddFunctor<c10::Half>, at::detail::Array<char*, int=3>>(int, c10::Half, at::native::AddFunctor<c10::Half>)",16,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::im2col4d_kernel<__half, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, __half const *, cudnnTensor4dStruct*)",11,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::im2col4d_kernel<__half, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, __half const *, cudnnTensor4dStruct*)",11,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (3)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::im2col4d_kernel<__half, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, __half const *, cudnnTensor4dStruct*)",11,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nhwcToNchwKernel<float, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, float const *, __half*, float, float)",9,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nhwcToNchwKernel<float, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, float const *, __half*, float, float)",9,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Mid (5)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void nhwcToNchwKernel<float, __half, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, float const *, __half*, float, float)",9,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg0_engine<__half, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, int=512>(int, int, int, __half const *, int, cudnn::cnn::wgrad_alg0_engine<__half, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, int=512>*, __half const , kernel_grad_params, __int64, int, float, int, int, int, int)",19,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg0_engine<__half, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, int=512>(int, int, int, __half const *, int, cudnn::cnn::wgrad_alg0_engine<__half, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, int=512>*, __half const , kernel_grad_params, __int64, int, float, int, int, int, int)",19,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","High (7)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg0_engine<__half, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, int=512>(int, int, int, __half const *, int, cudnn::cnn::wgrad_alg0_engine<__half, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, int=512>*, __half const , kernel_grad_params, __int64, int, float, int, int, int, int)",19,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<__half, int=0, int=5, int=6, int=4, int=3, int=4, bool=0, bool=1>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad2d_alg1_1<__half, int=0, int=5, int=6, int=4, int=3, int=4, bool=0, bool=1>*, kernel_grad_params, __int64, int, __int64, int, float, int, int)",7,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<__half, int=0, int=5, int=6, int=4, int=3, int=4, bool=0, bool=1>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad2d_alg1_1<__half, int=0, int=5, int=6, int=4, int=3, int=4, bool=0, bool=1>*, kernel_grad_params, __int64, int, __int64, int, float, int, int)",7,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (8)","High (9)","High (8)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<__half, int=0, int=5, int=6, int=4, int=3, int=4, bool=0, bool=1>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad2d_alg1_1<__half, int=0, int=5, int=6, int=4, int=3, int=4, bool=0, bool=1>*, kernel_grad_params, __int64, int, __int64, int, float, int, int)",7,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, __half>(cudnn::winograd_nonfused::WinogradDeltaParams<float, __half>)",14,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, __half>(cudnn::winograd_nonfused::WinogradDeltaParams<float, __half>)",14,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (3)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, __half>(cudnn::winograd_nonfused::WinogradDeltaParams<float, __half>)",14,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void foldedNhwcToNchwKernel<__half, __half, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, int, int, int, __half const *, __half*, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void foldedNhwcToNchwKernel<__half, __half, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, int, int, int, __half const *, __half*, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (4)","Mid (4)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void foldedNhwcToNchwKernel<__half, __half, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, int, int, int, __half const *, __half*, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<__half, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=0>(int, int, int, __half const *, int, float*, __half const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",4,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<__half, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=0>(int, int, int, __half const *, int, float*, __half const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",4,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (4)","Mid (4)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<__half, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=0>(int, int, int, __half const *, int, float*, __half const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",4,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg0_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, int=512>(int, int, int, __half const *, int, cudnn::cnn::wgrad_alg0_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, int=512>*, __half const , kernel_grad_params, __int64, int, float, int, int, int, int)",9,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg0_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, int=512>(int, int, int, __half const *, int, cudnn::cnn::wgrad_alg0_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, int=512>*, __half const , kernel_grad_params, __int64, int, float, int, int, int, int)",9,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","High (7)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg0_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, int=512>(int, int, int, __half const *, int, cudnn::cnn::wgrad_alg0_engine<__half, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, int=512>*, __half const , kernel_grad_params, __int64, int, float, int, int, int, int)",9,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void foldedNchwToNchwKernel<__half, __half, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, int, int, int, __half const *, __half*, int, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void foldedNchwToNchwKernel<__half, __half, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, int, int, int, __half const *, __half*, int, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (5)","Mid (5)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","void foldedNchwToNchwKernel<__half, __half, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, int, int, int, __half const *, __half*, int, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void gemmSN_NN_kernel<float, int=256, int=4, int=2, int=8, int=4, int=4, bool=0, cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half>>(cublasGemmSmallNParams<__half const , cublasGemvTensorStridedBatched<__half const >, float>)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void gemmSN_NN_kernel<float, int=256, int=4, int=2, int=8, int=4, int=4, bool=0, cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half>>(cublasGemmSmallNParams<__half const , cublasGemvTensorStridedBatched<__half const >, float>)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void gemmSN_NN_kernel<float, int=256, int=4, int=2, int=8, int=4, int=4, bool=0, cublasGemvTensorStridedBatched<__half const >, cublasGemvTensorStridedBatched<__half>>(cublasGemmSmallNParams<__half const , cublasGemvTensorStridedBatched<__half const >, float>)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, __half>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, __half>)",14,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, __half>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, __half>)",14,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (2)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, __half>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, __half>)",14,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_alg1_engine<__half, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=1>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad_alg1_engine<__half, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)",4,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_alg1_engine<__half, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=1>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad_alg1_engine<__half, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)",4,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Mid (5)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_alg1_engine<__half, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=1>(int, int, int, __half const *, int, __half const , int, cudnn::detail::dgrad_alg1_engine<__half, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)",4,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void transpose_readWrite_alignment_kernel<float2, float2, int=1, bool=0, int=6, int=4, int=4>(cublasTransposeParams<float2>, float2 const *, float2*, float2 const *)",6,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void transpose_readWrite_alignment_kernel<float2, float2, int=1, bool=0, int=6, int=4, int=4>(cublasTransposeParams<float2>, float2 const *, float2*, float2 const *)",6,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (2)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void transpose_readWrite_alignment_kernel<float2, float2, int=1, bool=0, int=6, int=4, int=4>(cublasTransposeParams<float2>, float2 const *, float2*, float2 const *)",6,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nchwToFoldedNhwcKernel<__half, __half, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",8,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nchwToFoldedNhwcKernel<__half, __half, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",8,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Mid (5)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void nchwToFoldedNhwcKernel<__half, __half, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, __half const *, __half*, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",8,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_s884cudnn_fp16_128x64_sliced1x4_ldg8_wgrad_idx_exp_interior_nhwc_nt_v1",4,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Low (2)","Low (3)","Low (2)"
"Tesla V100-PCIE-16GB (0)","volta_s884cudnn_fp16_128x64_sliced1x4_ldg8_wgrad_idx_exp_interior_nhwc_nt_v1",4,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","volta_s884cudnn_fp16_128x64_sliced1x4_ldg8_wgrad_idx_exp_interior_nhwc_nt_v1",4,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::AddFunctor<float>, at::detail::Array<char*, int=3>>(int, float, at::native::AddFunctor<float>)",124,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::AddFunctor<float>, at::detail::Array<char*, int=3>>(int, float, at::native::AddFunctor<float>)",124,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::AddFunctor<float>, at::detail::Array<char*, int=3>>(int, float, at::native::AddFunctor<float>)",124,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_256x64_ldg8_relu_f2f_exp_small_nhwc2nchw_tn_v1",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Mid (5)","Mid (6)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_256x64_ldg8_relu_f2f_exp_small_nhwc2nchw_tn_v1",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","volta_fp16_s884cudnn_fp16_256x64_ldg8_relu_f2f_exp_small_nhwc2nchw_tn_v1",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<__half, __half, int=512, int=6, int=8, int=3, int=3, int=5, int=1, bool=0, bool=1, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)",3,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<__half, __half, int=512, int=6, int=8, int=3, int=3, int=5, int=1, bool=0, bool=1, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)",3,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (7)","High (7)","High (7)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<__half, __half, int=512, int=6, int=8, int=3, int=3, int=5, int=1, bool=0, bool=1, bool=1>(int, int, int, __half const *, int, __half*, __half const *, kernel_conv_params, __int64, int, float, float, int, __half const *, __half const *, bool, int, int)",3,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, __half>(cudnn::winograd_nonfused::WinogradOutputParams<float, __half>)",18,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, __half>(cudnn::winograd_nonfused::WinogradOutputParams<float, __half>)",18,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Mid (6)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, __half>(cudnn::winograd_nonfused::WinogradOutputParams<float, __half>)",18,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
