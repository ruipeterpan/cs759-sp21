==33406== NVPROF is profiling process 33406, command: /home/ruipan/anaconda3/bin/python cv_benchmark.py --apex-amp O0 --model resnet18 --dataset cifar10 --batch-size 16 --epochs 1 --breakpoint 1
==33406== Some kernel(s) will be replayed on device 0 in order to collect all events/metrics.
==33406== Profiling application: /home/ruipan/anaconda3/bin/python cv_benchmark.py --apex-amp O0 --model resnet18 --dataset cifar10 --batch-size 16 --epochs 1 --breakpoint 1
==33406== Profiling result:
==33406== Metric result:
"Device","Kernel","Invocations","Metric Name","Metric Description","Min","Max","Avg"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)",9,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)",9,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Mid (6)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradForwardOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradOutputParams<float, float>)",9,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void flip_filter<float, float>(float*, float const *, int, int, int, int)",10,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void flip_filter<float, float>(float*, float const *, int, int, int, int)",10,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void flip_filter<float, float>(float*, float const *, int, int, int, int)",10,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (2)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradWgradDelta4x4<float, float>(cudnn::winograd_nonfused::WinogradDeltaParams<float, float>)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE0_clEvENKUlvE6_clEvEUlfE_NS_6detail5ArrayIPcLi2EEE16OffsetCalculatorILi1EjESC_NS0_6memory15LoadWithoutCastENSD_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE0_clEvENKUlvE6_clEvEUlfE_NS_6detail5ArrayIPcLi2EEE16OffsetCalculatorILi1EjESC_NS0_6memory15LoadWithoutCastENSD_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native27unrolled_elementwise_kernelIZZZNS0_21copy_device_to_deviceERNS_14TensorIteratorEbENKUlvE0_clEvENKUlvE6_clEvEUlfE_NS_6detail5ArrayIPcLi2EEE16OffsetCalculatorILi1EjESC_NS0_6memory15LoadWithoutCastENSD_16StoreWithoutCastEEEviT_T0_T1_T2_T3_T4_",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (2)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradWgradData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0>*, kernel_grad_params, __int64, int, __int64, int, float, int, int, int)",20,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0>*, kernel_grad_params, __int64, int, __int64, int, float, int, int, int)",20,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","High (8)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0>*, kernel_grad_params, __int64, int, __int64, int, float, int, int, int)",20,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg0_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, int=512>(int, int, int, float const *, int, cudnn::cnn::wgrad_alg0_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, int=512>*, float const , kernel_grad_params, __int64, int, float, int, int, int, int)",8,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg0_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, int=512>(int, int, int, float const *, int, cudnn::cnn::wgrad_alg0_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, int=512>*, float const , kernel_grad_params, __int64, int, float, int, int, int, int)",8,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","High (7)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg0_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, int=512>(int, int, int, float const *, int, cudnn::cnn::wgrad_alg0_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, int=512>*, float const , kernel_grad_params, __int64, int, float, int, int, int, int)",8,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void gemmSN_NN_kernel<float, int=256, int=4, int=2, int=8, int=4, int=4, bool=0, cublasGemvTensorStridedBatched<float const >, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<float const , cublasGemvTensorStridedBatched<float const >, float>)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void gemmSN_NN_kernel<float, int=256, int=4, int=2, int=8, int=4, int=4, bool=0, cublasGemvTensorStridedBatched<float const >, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<float const , cublasGemvTensorStridedBatched<float const >, float>)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void gemmSN_NN_kernel<float, int=256, int=4, int=2, int=8, int=4, int=4, bool=0, cublasGemvTensorStridedBatched<float const >, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<float const , cublasGemvTensorStridedBatched<float const >, float>)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void cunn_ClassNLLCriterion_updateGradInput_kernel<float>(float*, float*, long*, float*, float*, int, int, int, int, long)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, int=512>(int, int, int, float const *, int, cudnn::cnn::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, int=512>*, float const , kernel_grad_params, __int64, int, float, int, int, int, int)",8,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, int=512>(int, int, int, float const *, int, cudnn::cnn::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, int=512>*, float const , kernel_grad_params, __int64, int, float, int, int, int, int)",8,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","High (7)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, int=512>(int, int, int, float const *, int, cudnn::cnn::wgrad_alg0_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, int=512>*, float const , kernel_grad_params, __int64, int, float, int, int, int, int)",8,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=1, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_conv_params, __int64, int, float, float, int, float const *, float const *, bool, int, int)",42,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=1, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_conv_params, __int64, int, float, float, int, float const *, float const *, bool, int, int)",42,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","High (8)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<float, float, int=128, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=1, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_conv_params, __int64, int, float, float, int, float const *, float const *, bool, int, int)",42,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>(float, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnnTensorStruct, float const *, float, float const , float, cudnnTensorStruct*, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const *, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>*, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const *, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const , cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const , cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>(float, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnnTensorStruct, float const *, float, float const , float, cudnnTensorStruct*, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const *, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>*, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const *, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const , cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const , cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (2)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>(float, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>, cudnnTensorStruct, float const *, float, float const , float, cudnnTensorStruct*, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const *, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>*, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const *, cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const , cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1> const , cudnn::bn_bw_1C11_kernel_new<float, float, float2, int=512, bool=1, int=1>)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void foldedNchwToNchwKernel<float, float, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, int, int, int, float const *, float*, int, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void foldedNchwToNchwKernel<float, float, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, int, int, int, float const *, float*, int, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (4)","Mid (4)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void foldedNchwToNchwKernel<float, float, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, int, int, int, float const *, float*, int, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int=512, bool=1, int=1>(cudnnTensorStruct, float const *, cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int=512, bool=1, int=1>, cudnnTensorStruct*, float const *, float const , cudnnTensorStruct*, cudnnTensorStruct*, cudnnTensorStruct**, float const *, float const *, float const *, cudnnTensorStruct*, cudnnTensorStruct*)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int=512, bool=1, int=1>(cudnnTensorStruct, float const *, cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int=512, bool=1, int=1>, cudnnTensorStruct*, float const *, float const , cudnnTensorStruct*, cudnnTensorStruct*, cudnnTensorStruct**, float const *, float const *, float const *, cudnnTensorStruct*, cudnnTensorStruct*)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Low (3)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int=512, bool=1, int=1>(cudnnTensorStruct, float const *, cudnn::bn_fw_tr_1C11_kernel_NCHW<float, float, int=512, bool=1, int=1>, cudnnTensorStruct*, float const *, float const , cudnnTensorStruct*, cudnnTensorStruct*, cudnnTensorStruct**, float const *, float const *, float const *, cudnnTensorStruct*, cudnnTensorStruct*)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_128x32_nt",3,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_128x32_nt",3,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","High (7)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_128x32_nt",3,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_64x64<float, bool=0, bool=1>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_64x64<float, bool=0, bool=1>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Mid (5)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_64x64<float, bool=0, bool=1>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void pointwise_mult_and_sum_complex<float2, int=8, int=4>(float2*, float2*, float2*, int, int, int, int, int, float2)",4,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void pointwise_mult_and_sum_complex<float2, int=8, int=4>(float2*, float2*, float2*, int, int, int, int, int, float2)",4,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","High (7)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","void pointwise_mult_and_sum_complex<float2, int=8, int=4>(float2*, float2*, float2*, int, int, int, int, int, float2)",4,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x128_stridedB_splitK_medium_nn_v1",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x128_stridedB_splitK_medium_nn_v1",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (6)","High (7)","Mid (6)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x128_stridedB_splitK_medium_nn_v1",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1",16,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1",16,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (5)","Max (10)","High (9)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1",16,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (8)","High (9)","High (8)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x32_sliced1x4_ldg4_relu_exp_medium_nhwc_tn_v1",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=1, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_conv_params, __int64, int, float, float, int, float const *, float const *, bool, int, int)",3,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=1, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_conv_params, __int64, int, float, float, int, float const *, float const *, bool, int, int)",3,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Mid (5)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void implicit_convolve_sgemm<float, float, int=1024, int=5, int=5, int=3, int=3, int=3, int=1, bool=0, bool=1, bool=1>(int, int, int, float const *, int, float*, float const *, kernel_conv_params, __int64, int, float, float, int, float const *, float const *, bool, int, int)",3,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<float>, at::detail::Array<char*, int=1>>(int, float, at::native::FillFunctor<float>)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<float>, at::detail::Array<char*, int=1>>(int, float, at::native::FillFunctor<float>)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::FillFunctor<float>, at::detail::Array<char*, int=1>>(int, float, at::native::FillFunctor<float>)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_32x32<float, bool=0, bool=0, unsigned int=0, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)",16,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_32x32<float, bool=0, bool=0, unsigned int=0, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)",16,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Low (3)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_32x32<float, bool=0, bool=0, unsigned int=0, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)",16,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void explicit_convolve_sgemm<float, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>(int, int, int, float const *, int, float const *, int, float*, kernel_conv_params, __int64, int, __int64, int, float, float, int, float const *, float const *)",7,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void explicit_convolve_sgemm<float, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>(int, int, int, float const *, int, float const *, int, float*, kernel_conv_params, __int64, int, __int64, int, float, float, int, float const *, float const *)",7,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (4)","High (7)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void explicit_convolve_sgemm<float, int, int=1024, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>(int, int, int, float const *, int, float const *, int, float*, kernel_conv_params, __int64, int, __int64, int, float, float, int, float const *, float const *)",7,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)",40,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)",40,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (2)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void cudnn::ops::scalePackedTensor_kernel<float, float>(cudnnTensor4dStruct, float*, float)",40,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void cunn_ClassNLLCriterion_updateOutput_kernel<float, float>(float*, float*, float*, long*, float*, int, int, int, int, long)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=0>(int, int, int, float const *, int, float*, float const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",7,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=0>(int, int, int, float const *, int, float*, float const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",7,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (7)","High (8)","High (7)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=0>(int, int, int, float const *, int, float*, float const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",7,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nchwToFoldedNchwKernel<float, float, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, float const *, float*, int, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nchwToFoldedNchwKernel<float, float, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, float const *, float*, int, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Low (3)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void nchwToFoldedNchwKernel<float, float, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, float const *, float*, int, int, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>(int, int, int, float const *, int, float const *, int, float*, kernel_conv_params, __int64, int, __int64, int, float, float, int, float const *, float const *)",3,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>(int, int, int, float const *, int, float const *, int, float*, kernel_conv_params, __int64, int, __int64, int, float, float, int, float const *, float const *)",3,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","High (7)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","void explicit_convolve_sgemm<float, int, int=128, int=5, int=5, int=3, int=3, int=3, int=0, bool=0>(int, int, int, float const *, int, float const *, int, float*, kernel_conv_params, __int64, int, __int64, int, float, float, int, float const *, float const *)",3,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (2)","Low (1)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeBOffsetsKernel(cask_cudnn::ComputeBOffsetsParams)",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0>(int, int, int, float const *, int, float const *, int, float*, kernel_conv_params, __int64, int, __int64, int, float, float, int, float const *, float const *)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0>(int, int, int, float const *, int, float const *, int, float*, kernel_conv_params, __int64, int, __int64, int, float, float, int, float const *, float const *)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (8)","High (8)","High (8)"
"Tesla V100-PCIE-16GB (0)","void explicit_convolve_sgemm<float, int, int=128, int=6, int=7, int=3, int=3, int=5, int=0, bool=0>(int, int, int, float const *, int, float const *, int, float*, kernel_conv_params, __int64, int, __int64, int, float, float, int, float const *, float const *)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native13reduce_kernelILi256ELi2ENS0_8ReduceOpIfNS0_14func_wrapper_tIfZNS0_11sum_functorIfffEclERNS_14TensorIteratorEEUlffE_EEjfLi4EEEEEvT1_",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native13reduce_kernelILi256ELi2ENS0_8ReduceOpIfNS0_14func_wrapper_tIfZNS0_11sum_functorIfffEclERNS_14TensorIteratorEEUlffE_EEjfLi4EEEEEvT1_",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native13reduce_kernelILi256ELi2ENS0_8ReduceOpIfNS0_14func_wrapper_tIfZNS0_11sum_functorIfffEclERNS_14TensorIteratorEEUlffE_EEjfLi4EEEEEvT1_",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x64_stridedB_small_nn_v1",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x64_stridedB_small_nn_v1",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (8)","High (9)","High (8)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x64_stridedB_small_nn_v1",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<at::native::AddFunctor<long>>, at::detail::Array<char*, int=2>>(int, long, at::native::AddFunctor<long>)",20,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<at::native::AddFunctor<long>>, at::detail::Array<char*, int=2>>(int, long, at::native::AddFunctor<long>)",20,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::BUnaryFunctor<at::native::AddFunctor<long>>, at::detail::Array<char*, int=2>>(int, long, at::native::AddFunctor<long>)",20,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>(float, float, float, float, cudnnTensorStruct, float const *, cudnn::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, float const , cudnn::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float*, float const *, float const , float const , float, cudnn::reduced_divisor, int, float*, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",15,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>(float, float, float, float, cudnnTensorStruct, float const *, cudnn::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, float const , cudnn::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float*, float const *, float const , float const , float, cudnn::reduced_divisor, int, float*, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",15,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Mid (4)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>(float, float, float, float, cudnnTensorStruct, float const *, cudnn::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, float const , cudnn::bn_bw_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float*, float const *, float const , float const , float, cudnn::reduced_divisor, int, float*, cudnn::bnBwPersistentState*, int, float, float, float, int, float, cudnnStatus_t*, bool)",15,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<float, int=0, int=6, int=7, int=5, int=4, int=5, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad2d_alg1_1<float, int=0, int=6, int=7, int=5, int=4, int=5, bool=0, bool=1>*, kernel_grad_params, __int64, int, __int64, int, float, int, int)",6,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<float, int=0, int=6, int=7, int=5, int=4, int=5, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad2d_alg1_1<float, int=0, int=6, int=7, int=5, int=4, int=5, bool=0, bool=1>*, kernel_grad_params, __int64, int, __int64, int, float, int, int)",6,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (7)","High (8)","High (7)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<float, int=0, int=6, int=7, int=5, int=4, int=5, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad2d_alg1_1<float, int=0, int=6, int=7, int=5, int=4, int=5, bool=0, bool=1>*, kernel_grad_params, __int64, int, __int64, int, float, int, int)",6,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<float, bool=0, unsigned int=0, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",16,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<float, bool=0, unsigned int=0, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",16,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Mid (5)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<float, bool=0, unsigned int=0, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",16,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)",10,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)",10,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (2)","Low (1)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeOffsetsKernel(cask_cudnn::ComputeOffsetsParams)",10,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",9,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",9,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (3)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradForwardData4x4<float, float>(cudnn::winograd_nonfused::WinogradDataParams<float, float>)",9,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const *, cudnnTensor4dStruct*)",11,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const *, cudnnTensor4dStruct*)",11,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (3)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::im2col4d_kernel<float, long>(cudnn::cnn::im2col4d_params, cudnnConvolutionStruct, cudnnTensor4dStruct, float const *, cudnnTensor4dStruct*)",11,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_32x32<float, bool=1, bool=0, unsigned int=0, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)",6,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_32x32<float, bool=1, bool=0, unsigned int=0, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)",6,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Mid (4)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_32x32<float, bool=1, bool=0, unsigned int=0, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)",6,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_32x32<float, bool=0, bool=0, unsigned int=1, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)",11,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_32x32<float, bool=0, bool=0, unsigned int=1, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)",11,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Mid (5)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_32x32<float, bool=0, bool=0, unsigned int=1, bool=0, bool=0>(float*, float2 const *, int, int, int, int, int, int, int, int, int, float, float, cudnn::reduced_divisor, bool, float*, float*, int2, int, int)",11,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void _GLOBAL__N__54_tmpxft_000035b1_00000000_12_SoftMax_compute_80_cpp1_ii_a3310042::softmax_warp_backward<float, float, float, int=4, bool=1>(float*, float const *, float const , int, int, int)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void _GLOBAL__N__54_tmpxft_000035b1_00000000_12_SoftMax_compute_80_cpp1_ii_a3310042::softmax_warp_backward<float, float, float, int=4, bool=1>(float*, float const *, float const , int, int, int)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void _GLOBAL__N__54_tmpxft_000035b1_00000000_12_SoftMax_compute_80_cpp1_ii_a3310042::softmax_warp_backward<float, float, float, int=4, bool=1>(float*, float const *, float const , int, int, int)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nchwToNhwcKernel<float, float, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, float const *, float*, float, float)",10,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nchwToNhwcKernel<float, float, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, float const *, float*, float, float)",10,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Mid (6)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void nchwToNhwcKernel<float, float, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, float const *, float*, float, float)",10,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nhwcToNchwKernel<float, float, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, float const *, float*, float, float)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nhwcToNchwKernel<float, float, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, float const *, float*, float, float)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (3)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void nhwcToNchwKernel<float, float, float, bool=1, bool=0, cudnnKernelDataType_t=0>(int, int, int, int, float const *, float*, float, float)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (5)","Mid (5)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x32_stridedB_splitK_xregs_large_nn_v1",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (2)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradWgradOutput4x4<float, float>(cudnn::winograd_nonfused::WinogradWgradOutputParams<float, float>)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=0>(int, int, int, float const *, int, float*, float const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",4,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=0>(int, int, int, float const *, int, float*, float const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",4,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (4)","Mid (4)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=0>(int, int, int, float const *, int, float*, float const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",4,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1",3,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1",3,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (9)","Max (10)","High (9)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1",3,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_64x64_nn",4,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_64x64_nn",4,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","High (9)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_64x64_nn",4,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_16x16<float>(float2*, float const *, int, int, int, int, int, int, int, int)",12,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_16x16<float>(float2*, float const *, int, int, int, int, int, int, int, int)",12,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Mid (4)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_16x16<float>(float2*, float const *, int, int, int, int, int, int, int, int)",12,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_alg1_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_alg1_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_alg1_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_alg1_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (2)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_alg1_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_alg1_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x32_relu_medium_nn_v1",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x32_relu_medium_nn_v1",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Mid (4)","Low (3)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x32_relu_medium_nn_v1",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void wgrad2d_grouped_direct_kernel<float, float, float, cudnnTensorFormat_t=0>(cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void wgrad2d_grouped_direct_kernel<float, float, float, cudnnTensorFormat_t=0>(cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (4)","Mid (4)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void wgrad2d_grouped_direct_kernel<float, float, float, cudnnTensorFormat_t=0>(cudnnTensorStruct, float const *, cudnnTensorStruct, float const *, cudnnConvolutionStruct, cudnnFilterStruct, float*, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor, int)",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void _GLOBAL__N__54_tmpxft_000035b1_00000000_12_SoftMax_compute_80_cpp1_ii_a3310042::softmax_warp_forward<float, float, float, int=4, bool=1>(float*, float const *, int, int, int)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void _GLOBAL__N__54_tmpxft_000035b1_00000000_12_SoftMax_compute_80_cpp1_ii_a3310042::softmax_warp_forward<float, float, float, int=4, bool=1>(float*, float const *, int, int, int)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void _GLOBAL__N__54_tmpxft_000035b1_00000000_12_SoftMax_compute_80_cpp1_ii_a3310042::softmax_warp_forward<float, float, float, int=4, bool=1>(float*, float const *, int, int, int)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_64x64_nt",6,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_64x64_nt",6,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (5)","High (8)","Mid (6)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_64x64_nt",6,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native29vectorized_elementwise_kernelILi4EZNS0_21threshold_kernel_implIfEEvRNS_14TensorIteratorET_S5_EUlffE_NS_6detail5ArrayIPcLi3EEEEEviT0_T1_",34,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native29vectorized_elementwise_kernelILi4EZNS0_21threshold_kernel_implIfEEvRNS_14TensorIteratorET_S5_EUlffE_NS_6detail5ArrayIPcLi3EEEEEviT0_T1_",34,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","_ZN2at6native29vectorized_elementwise_kernelILi4EZNS0_21threshold_kernel_implIfEEvRNS_14TensorIteratorET_S5_EUlffE_NS_6detail5ArrayIPcLi3EEEEEviT0_T1_",34,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_cgemm_64x32_tn",7,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_cgemm_64x32_tn",7,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (7)","Max (10)","High (9)"
"Tesla V100-PCIE-16GB (0)","volta_cgemm_64x32_tn",7,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void gemmSN_TN_kernel_64addr<float, int=128, int=16, int=2, int=4, int=8, int=9, bool=0, cublasGemvTensorStridedBatched<float const >, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<float const , cublasGemvTensorStridedBatched<float const >, float>)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void gemmSN_TN_kernel_64addr<float, int=128, int=16, int=2, int=4, int=8, int=9, bool=0, cublasGemvTensorStridedBatched<float const >, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<float const , cublasGemvTensorStridedBatched<float const >, float>)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void gemmSN_TN_kernel_64addr<float, int=128, int=16, int=2, int=4, int=8, int=9, bool=0, cublasGemvTensorStridedBatched<float const >, cublasGemvTensorStridedBatched<float>>(cublasGemmSmallNParams<float const , cublasGemvTensorStridedBatched<float const >, float>)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x64_stridedB_splitK_small_nn_v1",3,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x64_stridedB_splitK_small_nn_v1",3,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (7)","High (7)","High (7)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x64_stridedB_splitK_small_nn_v1",3,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<float, bool=0, unsigned int=1, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",22,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<float, bool=0, unsigned int=1, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",22,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Mid (6)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<float, bool=0, unsigned int=1, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",22,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<float, bool=1, unsigned int=0, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",5,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<float, bool=1, unsigned int=0, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",5,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (4)","Mid (5)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<float, bool=1, unsigned int=0, bool=0>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",5,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)",9,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)",9,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (2)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd_nonfused::winogradForwardFilter4x4<float, float>(cudnn::winograd_nonfused::WinogradFilterParams<float, float>)",9,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nchwAddPaddingKernel<float, float, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, int, int, int, int, float const *, float*, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void nchwAddPaddingKernel<float, float, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, int, int, int, int, float const *, float*, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (2)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void nchwAddPaddingKernel<float, float, float, bool=1, cudnnKernelDataType_t=0>(int, int, int, int, int, int, int, int, float const *, float*, int, int, int, int, int, float, float, cudnn::reduced_divisor, cudnn::reduced_divisor, cudnn::reduced_divisor)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<float, int=0, int=5, int=6, int=4, int=3, int=4, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad2d_alg1_1<float, int=0, int=5, int=6, int=4, int=3, int=4, bool=0, bool=1>*, kernel_grad_params, __int64, int, __int64, int, float, int, int)",6,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<float, int=0, int=5, int=6, int=4, int=3, int=4, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad2d_alg1_1<float, int=0, int=5, int=6, int=4, int=3, int=4, bool=0, bool=1>*, kernel_grad_params, __int64, int, __int64, int, float, int, int)",6,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (8)","High (9)","High (8)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad2d_alg1_1<float, int=0, int=5, int=6, int=4, int=3, int=4, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad2d_alg1_1<float, int=0, int=5, int=6, int=4, int=3, int=4, bool=0, bool=1>*, kernel_grad_params, __int64, int, __int64, int, float, int, int)",6,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd::generateWinogradTilesKernel<int=0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",16,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd::generateWinogradTilesKernel<int=0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",16,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (3)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void cudnn::winograd::generateWinogradTilesKernel<int=0, float, float>(cudnn::winograd::GenerateWinogradTilesParams<float, float>)",16,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, int=2>, OffsetCalculator<int=1, unsigned int>, OffsetCalculator<int=1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, float, float, at::native::MulScalarFunctor<float, float>, char*, int=2, at::detail::Array<char*, int=2>)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, int=2>, OffsetCalculator<int=1, unsigned int>, OffsetCalculator<int=1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, float, float, at::native::MulScalarFunctor<float, float>, char*, int=2, at::detail::Array<char*, int=2>)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void at::native::unrolled_elementwise_kernel<at::native::MulScalarFunctor<float, float>, at::detail::Array<char*, int=2>, OffsetCalculator<int=1, unsigned int>, OffsetCalculator<int=1, unsigned int>, at::native::memory::LoadWithoutCast, at::native::memory::StoreWithoutCast>(int, float, float, at::native::MulScalarFunctor<float, float>, char*, int=2, at::detail::Array<char*, int=2>)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x128_relu_medium_nn_v1",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x128_relu_medium_nn_v1",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (7)","High (7)","High (7)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x128_relu_medium_nn_v1",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, int=512>(int, int, int, float const *, int, cudnn::cnn::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, int=512>*, float const , kernel_grad_params, __int64, int, float, int, int, int, int)",12,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, int=512>(int, int, int, float const *, int, cudnn::cnn::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, int=512>*, float const , kernel_grad_params, __int64, int, float, int, int, int, int)",12,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","High (8)","Mid (4)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, int=512>(int, int, int, float const *, int, cudnn::cnn::wgrad_alg0_engine<float, int=512, int=6, int=5, int=3, int=3, int=3, bool=0, int=512>*, float const , kernel_grad_params, __int64, int, float, int, int, int, int)",12,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)",16,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)",16,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeWgradSplitKOffsetsKernel(cask_cudnn::ComputeSplitKOffsetsParams)",16,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=0>(int, int, int, float const *, int, float*, float const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",7,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=0>(int, int, int, float const *, int, float*, float const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",7,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (3)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::cnn::wgrad_alg1_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=0>(int, int, int, float const *, int, float*, float const , kernel_grad_params, __int64, int, float, float, int, int, int*, kernel_grad_params, int, int)",7,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_16x16<float, bool=0>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",6,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_16x16<float, bool=0>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",6,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Mid (4)","Low (3)"
"Tesla V100-PCIE-16GB (0)","void fft2d_c2r_16x16<float, bool=0>(float*, float2*, int, int, int, int, int, int, int, int, int, int, float, float, int, float*, float*)",6,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_gcgemm_64x32_nt",30,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_gcgemm_64x32_nt",30,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (5)","Max (10)","High (8)"
"Tesla V100-PCIE-16GB (0)","volta_gcgemm_64x32_nt",30,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)",16,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)",16,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","cask_cudnn::computeWgradBOffsetsKernel(cask_cudnn::ComputeWgradBOffsetsParams)",16,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_32x128_nn",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_32x128_nn",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (8)","High (8)","High (8)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_32x128_nn",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_alg1_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_alg1_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)",2,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_alg1_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_alg1_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)",2,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (6)","Mid (6)","Mid (6)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_alg1_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_alg1_engine<float, int=128, int=5, int=5, int=3, int=3, int=3, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)",2,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_fw_tr_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>(cudnnTensorStruct, float const *, cudnn::bn_fw_tr_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",15,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_fw_tr_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>(cudnnTensorStruct, float const *, cudnn::bn_fw_tr_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",15,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Mid (4)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void cudnn::bn_fw_tr_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>(cudnnTensorStruct, float const *, cudnn::bn_fw_tr_1C11_singleread<float, int=512, bool=1, int=1, int=2, int=0>, cudnnTensorStruct*, float const *, float const , float, float, float*, float const *, float const *, float const *, float, float, cudnn::reduced_divisor, int, float*, cudnn::bnFwPersistentState*, int, float, float, float, int, float, float, cudnnStatus_t*, bool)",15,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void transpose_readWrite_alignment_kernel<float2, float2, int=1, bool=0, int=6, int=4, int=4>(cublasTransposeParams<float2>, float2 const *, float2*, float2 const *)",3,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void transpose_readWrite_alignment_kernel<float2, float2, int=1, bool=0, int=6, int=4, int=4>(cublasTransposeParams<float2>, float2 const *, float2*, float2 const *)",3,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (2)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void transpose_readWrite_alignment_kernel<float2, float2, int=1, bool=0, int=6, int=4, int=4>(cublasTransposeParams<float2>, float2 const *, float2*, float2 const *)",3,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::AddFunctor<float>, at::detail::Array<char*, int=3>>(int, float, at::native::AddFunctor<float>)",140,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::AddFunctor<float>, at::detail::Array<char*, int=3>>(int, float, at::native::AddFunctor<float>)",140,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (1)","Low (1)","Low (1)"
"Tesla V100-PCIE-16GB (0)","void at::native::vectorized_elementwise_kernel<int=4, at::native::AddFunctor<float>, at::detail::Array<char*, int=3>>(int, float, at::native::AddFunctor<float>)",140,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_alg1_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_alg1_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)",4,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_alg1_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_alg1_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)",4,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (4)","Mid (6)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","void cudnn::detail::dgrad_alg1_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=1>(int, int, int, float const *, int, float const , int, cudnn::detail::dgrad_alg1_engine<float, int=128, int=6, int=7, int=3, int=3, int=5, bool=0, bool=1>*, kernel_grad_params, __int64, int, float, int)",4,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, int=4>>(float)",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, int=4>>(float)",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (2)","Low (2)","Low (2)"
"Tesla V100-PCIE-16GB (0)","void at::native::reduce_kernel<int=512, int=1, at::native::ReduceOp<float, at::native::MeanOps<float, float>, unsigned int, float, int=4>>(float)",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_32x128_nt",1,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_32x128_nt",1,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (8)","High (8)","High (8)"
"Tesla V100-PCIE-16GB (0)","volta_sgemm_32x128_nt",1,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_64x64<float, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int)",10,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_64x64<float, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int)",10,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Mid (6)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_64x64<float, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int)",10,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<float, bool=0, unsigned int=1, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",8,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<float, bool=0, unsigned int=1, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",8,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Low (3)","Mid (6)","Mid (5)"
"Tesla V100-PCIE-16GB (0)","void fft2d_r2c_32x32<float, bool=0, unsigned int=1, bool=1>(float2*, float const *, int, int, int, int, int, int, int, int, int, cudnn::reduced_divisor, bool, int2, int, int)",8,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x32_stridedB_splitK_small_nn_v1",3,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x32_stridedB_splitK_small_nn_v1",3,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","Mid (6)","High (7)","Mid (6)"
"Tesla V100-PCIE-16GB (0)","volta_scudnn_128x32_stridedB_splitK_small_nn_v1",3,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_cgemm_32x64_tn",3,"tensor_precision_fu_utilization","Tensor-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
"Tesla V100-PCIE-16GB (0)","volta_cgemm_32x64_tn",3,"single_precision_fu_utilization","Single-Precision Function Unit Utilization","High (7)","High (8)","High (7)"
"Tesla V100-PCIE-16GB (0)","volta_cgemm_32x64_tn",3,"double_precision_fu_utilization","Double-Precision Function Unit Utilization","Idle (0)","Idle (0)","Idle (0)"
